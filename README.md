#  Tree of Clarifications (ToC)

This is the official repository for our EMNLP 2023 paper:
[Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2310.14696)

<div align="center">
  <img alt="ToC Overview" src="https://github.com/gankim/tree-of-clarifications/blob/main/assets/overview.png" width="400px">
</div>

## Summary
We propose a novel framework, <b>Tree of Clarifications (ToC)</b> designed for generating long-form answers to ambiguous questions.
- It guides LLMs to explore diverse interpretations of ambiguity in <u>a tree structure with the ability to prune</u> unhelpful ones
-  We investigate combining <u>retrieval-augmented generation (RAG) with LLM</u> and achieve the state-of-the-art performance on ASQA

## Environments

To facilitate a smooth setup, we suggest creating a Conda environment using the provided configuration:

### Option 1. try creating it from yml file
```
conda env create -f environment.yml
pip install apple-interlinked --index-url https://pypi.apple.com/simple
conda activate toc
```

### Option 2. Try creating it from scratch (if the first option fails)

```
conda create --name toc python=3.11
pip install apple-interlinked --index-url https://pypi.apple.com/simple
pip install -r requirements.txt
conda activate toc
```


Patch wikiextractor with the following command
```
python patch_wikiextractor.py
```

## Preparing the Dataset (Skip as it's already prepared)
Access and download the ASQA dataset [here](https://github.com/google-research/language/tree/master/language/asqa) or utilize the pre-packaged version in our repository at `./asqa/ASQA.json`

### Integrating DuckDuckGo Search Engine Results
ToC is capable of incorporating search results from external sources, such as DuckDuckGo search engine, to enhance answer quality. Follow the script below to fetch search results, or use our pre-compiled dataset at ./search/results.json. Omitting this step is an option but may slightly impact ToC's performance.

**No API credentials required** - DuckDuckGo search works without API keys!

Set the directory paths for the ASQA dataset and search results. Run the following script to search Wikipedia documents relevant to ambiguous questions and save the results in `$SEARCH_DIR`.

```
export ASQA_DIR='/Users/ruochen/Documents/research/Clarity/uncertain-rag/dataset/asqa' # directory path to the ASQA dataset
export SEARCH_DIR='/Users/ruochen/Documents/research/Clarity/tree-of-clarifications/assets/search results' # directory path to search results

python duckduckgo_search.py \
    --data_dir $ASQA_DIR \
    --output_dir $SEARCH_DIRÃŸ
```

## Answering ambiguous questions with ToC


To run ToC, use the following script, specifying the necessary paths and options:
```
export GEMINI_KEY= # interlinked API key
export ASQA_DIR="/Users/ruochen/Documents/research/Clarity/tree-of-clarifications/assets/asqa"
export OUT_DIR="/Users/ruochen/Documents/research/Clarity/tree-of-clarifications/assets"
export SEARCH_PATH="/Users/ruochen/Documents/research/Clarity/tree-of-clarifications/assets/search results/output.json"

caffeinate -d python run_toc.py \
    --data_dir $ASQA_DIR \
    --search_path $SEARCH_PATH \
    --verify \
    --output_dir $OUT_DIR \
    --use_wikipedia \
```

## If you'd like to modify the interlinked method

If you have a different way of calling LLMs, 
1. modify the wrapper in dsp/modules/gemini.py
2. (optional) change the instantiation in L251, run_toc.py: lm = dsp.Gemini(model=args.model_type, api_key=args.gemini_key)

## Evaluating the long-form answers

To evaluate the answers generated by ToC, follow the guidelines provided in the [official ASQA repository](https://github.com/google-research/language/tree/master/language/asqa).

## Reference
```
@article{kim2023tree,
  title={Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models},
  author={Gangwoo Kim and Sungdong Kim and Byeongguk Jeon and Joonsuk Park and Jaewoo Kang},
  journal={EMNLP},
  year={2023}
}
```
